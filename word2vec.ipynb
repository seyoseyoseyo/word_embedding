{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import string\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from scipy.special import expit as sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy\n",
      "  Downloading scipy-1.5.2-cp37-cp37m-win_amd64.whl (31.2 MB)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\mazic\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from scipy) (1.18.1)\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.5.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\mazic\\appdata\\local\\programs\\python\\python37\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(s):\n",
    "  return s.translate(str.maketrans('','',string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_wiki():\n",
    "  V = 20\n",
    "  files = glob('large_files/enwiki*.txt')\n",
    "  all_word_counts = {}\n",
    "  for f in files:\n",
    "    for line in open(f, encoding=\"utf8\"):\n",
    "      if line and line[0] not in '[*-|=\\{\\}':\n",
    "        s = remove_punctuation(line).lower().split()\n",
    "        if len(s) > 1:\n",
    "          for word in s:\n",
    "            if word not in all_word_counts:\n",
    "              all_word_counts[word] = 0\n",
    "            all_word_counts[word] += 1\n",
    "  V = min(V, len(all_word_counts))\n",
    "  all_word_counts = sorted(all_word_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "  top_words = [w for w, count in all_word_counts[:V-1]] + ['<UNK>']\n",
    "  word2idx = {w: i for i, w in enumerate(top_words)}\n",
    "  unk = word2idx['<UNK>']\n",
    "  \n",
    "  sents = []\n",
    "  for f in files:\n",
    "    for line in open(f, encoding=\"utf8\"):\n",
    "      if line and line[0] not in '[*-|=\\{\\}':\n",
    "        s = remove_punctuation(line).lower().split()\n",
    "        if len(s) > 1:\n",
    "          sent = [word2idx[w] if w in word2idx else unk for w in s]\n",
    "          sents.append(sent)\n",
    "  return sents, word2idx\n",
    "          \n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_wiki_small():\n",
    "  V = 20\n",
    "  file = 'large_files/enwiki-20180401-pages-articles1.xml-p10p30302-01.txt'\n",
    "  all_word_counts = {}\n",
    "  i = 0\n",
    "  for line in open(file, encoding=\"utf8\"):\n",
    "    if (i < 10): \n",
    "      if line and line[0] not in '[*-|=\\{\\}':\n",
    "        s = remove_punctuation(line).lower().split()\n",
    "        if len(s) > 1:\n",
    "          i += 1\n",
    "          for word in s:\n",
    "            if word not in all_word_counts:\n",
    "              all_word_counts[word] = 0\n",
    "            all_word_counts[word] += 1\n",
    "            \n",
    "  V = min(V, len(all_word_counts))\n",
    "  all_word_counts = sorted(all_word_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "  top_words = [w for w, count in all_word_counts[:V-1]] + ['<UNK>']\n",
    "  word2idx = {w: i for i, w in enumerate(top_words)}\n",
    "  unk = word2idx['<UNK>']\n",
    "  \n",
    "  sents = []\n",
    "  i = 0\n",
    "  for line in open(file, encoding=\"utf8\"):\n",
    "    if (i < 10): \n",
    "      if line and line[0] not in '[*-|=\\{\\}':\n",
    "        s = remove_punctuation(line).lower().split()\n",
    "        if len(s) > 1:\n",
    "          i += 1\n",
    "          sent = [word2idx[w] if w in word2idx else unk for w in s]\n",
    "          sents.append(sent)\n",
    "  return sents, word2idx\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_negative_sampling_distribution(sentences, vocab_size):\n",
    "  word_freq = np.zeros(vocab_size)\n",
    "  \n",
    "  for sentence in sentences:\n",
    "      for word in sentence:\n",
    "          word_freq[word] += 1\n",
    "\n",
    "  # smooth it\n",
    "  p_neg = word_freq**0.75\n",
    "\n",
    "  # normalize it\n",
    "  p_neg = p_neg / p_neg.sum()\n",
    "\n",
    "  assert(np.all(p_neg > 0))\n",
    "  return p_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_context(pos, sentence, window_size):\n",
    "  start = max(0, pos - window_size)\n",
    "  end_  = min(len(sentence), pos + window_size)\n",
    "\n",
    "  context = []\n",
    "  for ctx_pos, ctx_word_idx in enumerate(sentence[start:end_], start=start):\n",
    "    if ctx_pos != pos:\n",
    "      context.append(ctx_word_idx)\n",
    "  return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def sgd(input_, targets, label, learning_rate, W, V):\n",
    "  # W[input_] shape: D\n",
    "  # V[:,targets] shape: D x N\n",
    "  # activation shape: N\n",
    "  # print(\"input_:\", input_, \"targets:\", targets)\n",
    "  activation = W[input_].dot(V[:,targets])\n",
    "  prob = sigmoid(activation)\n",
    "\n",
    "  # gradients\n",
    "  gV = np.outer(W[input_], prob - label) # D x N\n",
    "  gW = np.sum((prob - label)*V[:,targets], axis=1) # D\n",
    "\n",
    "  V[:,targets] -= learning_rate*gV # D x N\n",
    "  W[input_] -= learning_rate*gW # D\n",
    "\n",
    "  # return cost (binary cross entropy)\n",
    "  cost = label * np.log(prob + 1e-10) + (1 - label) * np.log(1 - prob + 1e-10)\n",
    "  return cost.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train_model():\n",
    "  sentences, word2idx = get_wiki_small()\n",
    "  vocab_size = len(word2idx)\n",
    "  \n",
    "  window_size = 5\n",
    "  learning_rate = 0.025\n",
    "  final_learning_rate = 0.0001\n",
    "  num_negatives = 5\n",
    "  epochs = 20\n",
    "  D = 5\n",
    "  \n",
    "  learning_rate_delta = (learning_rate - final_learning_rate) / epochs\n",
    "  \n",
    "  W = np.random.randn(vocab_size, D)\n",
    "  V = np.random.randn(D, vocab_size)\n",
    "  \n",
    "  p_neg = get_negative_sampling_distribution(sentences, vocab_size)\n",
    "  costs = []\n",
    "  \n",
    "  threshold = 1e-5\n",
    "  p_drop = 1 - np.sqrt(threshold / p_neg)\n",
    "  \n",
    "  for epoch in range(epochs):\n",
    "    np.random.shuffle(sentences)\n",
    "    cost = 0\n",
    "    counter = 0\n",
    "    t0 = datetime.now()\n",
    "    for sentence in sentences:\n",
    "      sentence = [w for w in sentence if np.random.random() < (1 - p_drop[w])]\n",
    "      if len(sentence) < 2:\n",
    "        continue\n",
    "      randomly_ordered_positions = np.random.choice(\n",
    "        len(sentence),\n",
    "        size=len(sentence),\n",
    "        replace=False,\n",
    "      )\n",
    "      \n",
    "      for pos in randomly_ordered_positions:\n",
    "        word = sentence[pos]\n",
    "        context_words = get_context(pos, sentence, window_size)\n",
    "        neg_word = np.random.choice(vocab_size, p=p_neg)\n",
    "        targets = np.array(context_words)\n",
    "        \n",
    "        c = sgd(word, targets, 1, learning_rate, W, V)\n",
    "        cost += c\n",
    "        c = sgd(neg_word, targets, 0, learning_rate, W, V)\n",
    "        cost += c\n",
    "      counter += 1\n",
    "      if counter % 100 == 0:\n",
    "        print(\"processed %s / %s\\r\" % (counter, len(sentences)))\n",
    "    \n",
    "    dt = datetime.now() - t0\n",
    "    print(\"epoch complete:\", epoch, \"cost:\", cost, \"dt:\", dt)\n",
    "\n",
    "    # save the cost\n",
    "    costs.append(cost)\n",
    "\n",
    "    # update the learning rate\n",
    "    learning_rate -= learning_rate_delta\n",
    "\n",
    "  # return the model\n",
    "  return word2idx, W, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19, 3, 19, 19, 19, 19, 19, 19, 12, 19, 12, 19, 19, 19], [3, 10, 8, 12, 16, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 5, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 5, 19, 19, 19, 19, 9, 19, 19, 3, 19, 0, 19, 7, 19, 19, 19, 4, 19], [19, 19, 7, 0, 19, 10, 19, 3, 19, 19, 19, 19, 9, 19, 19, 2, 0, 19, 1, 19, 19, 19, 3, 10, 19, 19, 8, 19, 19, 4, 19, 1, 6, 19, 4, 6, 19, 16, 19, 19, 19, 1, 19, 19, 19, 19, 9, 19, 19], [3, 19, 19, 19, 8, 19, 19, 1, 19, 11, 8, 19, 19, 19, 19, 19, 19, 4, 19, 5, 8, 16, 19, 19, 4, 19, 1, 3, 19, 19, 19, 1, 19, 19, 19, 19, 6, 19, 1, 19, 19, 19, 19, 19, 19, 11, 19, 19, 7, 19, 19, 19, 1, 3, 19, 19, 19, 19, 19, 0, 19, 1, 19, 4, 19, 3, 9, 19, 19, 19], [0, 17, 3, 10, 19, 11, 0, 17, 19, 4, 0, 19, 19, 19, 19, 19, 11, 0, 19, 19, 19, 19, 11, 19, 19, 19, 19, 19, 19, 11, 0, 19, 19, 19, 19, 19, 19, 4, 19, 19, 19, 19, 19, 19, 19, 9, 19, 19, 19, 19, 19, 19, 19, 4, 0, 19, 19, 9, 19, 19, 19, 11, 0, 19, 19, 19, 19, 19, 0, 13, 19, 18, 1, 19, 17, 14, 2, 19, 19, 19, 19, 0, 19, 19, 19, 19, 5, 19, 5, 19, 19, 19, 0, 19, 19, 19, 19, 19, 19, 1, 19, 19, 19, 19, 19, 19, 19, 1, 0, 19, 19, 19, 19, 19, 7, 0, 6, 19, 1, 0, 19, 19, 19, 5, 19, 19, 4, 19, 19, 19, 19, 19, 19, 18, 0, 17, 6, 9, 3, 2, 19, 19, 9, 19, 19], [0, 13, 12, 19, 7, 19, 19, 19, 6, 14, 19, 19, 19, 0, 19, 19, 1, 3, 2, 0, 19, 19, 19, 0, 19, 4, 19, 2, 19, 0, 19, 19, 19, 19, 19, 19, 5, 8, 19, 19, 3, 4, 14, 19, 19, 19, 2, 19, 19, 19, 0, 19, 2, 0, 19, 19, 19, 19, 18, 5, 8, 19, 10, 19, 19, 19, 0, 19, 19, 19, 0, 19, 19, 19, 18, 19, 7, 19, 7, 19, 19, 19, 16, 19, 19, 7, 19, 19, 3, 5, 19, 3], [0, 19, 6, 19, 19, 19, 19, 2, 0, 19, 19, 19, 19, 0, 19, 1, 19, 19, 19, 4, 2, 19, 19, 15, 19, 4, 19, 19, 19, 16, 19, 19, 19, 15, 19, 19, 5, 6, 19, 19, 8, 19, 19, 10, 19, 2, 19, 8, 19, 19, 19, 8, 19, 1, 8, 19, 19, 1, 19, 4, 0, 19, 5, 19, 5, 19, 19, 19, 1, 19, 0, 19, 1, 19, 19, 19, 19, 19, 19, 10, 19, 19, 0, 13, 6, 2, 0, 19, 6, 19, 19, 19, 19, 0, 19, 19, 1, 19, 14, 19, 19, 4, 0, 13, 6, 19, 14, 19, 1, 0, 19, 2, 19, 19, 19, 19, 19, 1, 19, 19, 19, 19, 19, 0, 19, 19, 19, 19, 0, 19, 19, 0, 19, 19, 19, 0, 19, 10, 8, 19, 19, 19, 19, 19, 0, 19, 19], [0, 19, 19, 12, 19, 19, 19, 19, 19, 19, 2, 19, 19, 19, 19, 0, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 6, 19, 0, 19, 19, 19, 19, 19, 4, 19, 19, 0, 19, 19, 19, 15, 19, 19, 5, 19, 6, 19, 19, 2, 0, 19, 19, 2, 19, 0, 19, 6, 13, 19, 0, 19, 19, 2, 19, 19, 0, 19, 19, 19, 5, 8, 19, 1, 19, 19, 15, 19, 19, 19, 19, 19, 15, 0, 19, 1, 0, 19, 19, 19, 19, 5, 0, 19, 19, 19, 7, 18, 0, 19, 19, 2, 19, 7, 19, 19, 1, 19, 19, 19, 19, 5, 19, 15, 0, 19, 1, 0, 19, 19, 0, 19, 17, 3, 19, 19, 19, 19, 19, 19], [19, 3, 19, 11, 0, 19, 9, 19, 19, 1, 0, 19, 19, 19, 19, 19, 19, 0, 19, 19, 1, 19], [5, 19, 1, 0, 12, 19, 1, 0, 19, 2, 0, 19, 1, 0, 19, 19, 19, 19, 19, 0, 13, 19, 1, 19, 6, 19, 19, 7, 19, 19, 19, 14, 0, 13, 7, 19, 0, 12, 4, 19, 19, 1, 3, 19, 19, 19, 19, 19, 19, 19, 19, 7, 0, 19, 19, 2, 19, 19, 19, 19, 19, 19, 6, 19, 7, 19, 19, 19, 19]] {'the': 0, 'of': 1, 'in': 2, 'anarchism': 3, 'and': 4, 'as': 5, 'anarchist': 6, 'to': 7, 'a': 8, 'or': 9, 'is': 10, 'from': 11, 'political': 12, 'first': 13, 'was': 14, 'by': 15, 'philosophy': 16, 'word': 17, 'use': 18, '<UNK>': 19}\n"
     ]
    }
   ],
   "source": [
    "sentences, word2idx = get_wiki_small()\n",
    "print(sentences, word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch complete: 0 cost: -15.264472271784413 dt: 0:00:00.001001\n",
      "epoch complete: 1 cost: -29.614341482538222 dt: 0:00:00.002989\n",
      "epoch complete: 2 cost: -10.962995073739663 dt: 0:00:00.000961\n",
      "epoch complete: 3 cost: -10.437147104361781 dt: 0:00:00.000998\n",
      "epoch complete: 4 cost: -4.768189741953256 dt: 0:00:00.001028\n",
      "epoch complete: 5 cost: -44.334816238657446 dt: 0:00:00.001997\n",
      "epoch complete: 6 cost: -1.1587330323231546 dt: 0:00:00.001031\n",
      "epoch complete: 7 cost: -21.696532680766865 dt: 0:00:00.001996\n",
      "epoch complete: 8 cost: -63.79827152943896 dt: 0:00:00.002944\n",
      "epoch complete: 9 cost: -81.19862030117831 dt: 0:00:00.003007\n",
      "epoch complete: 10 cost: -10.806632059104425 dt: 0:00:00.001005\n",
      "epoch complete: 11 cost: -13.832729191596421 dt: 0:00:00.000998\n",
      "epoch complete: 12 cost: -12.76264452732396 dt: 0:00:00.000983\n",
      "epoch complete: 13 cost: -14.868321482498917 dt: 0:00:00.000996\n",
      "epoch complete: 14 cost: -7.0466905703664064 dt: 0:00:00.001992\n",
      "epoch complete: 15 cost: 0 dt: 0:00:00.001025\n",
      "epoch complete: 16 cost: -47.46128871785956 dt: 0:00:00.001968\n",
      "epoch complete: 17 cost: -36.915606872138476 dt: 0:00:00.001993\n",
      "epoch complete: 18 cost: -13.452302615814201 dt: 0:00:00.000997\n",
      "epoch complete: 19 cost: -27.528737624550235 dt: 0:00:00.001968\n",
      "[[ 1.50862     0.47303746  1.13638425  2.2043093   1.63981897]\n",
      " [-0.89781739  0.99153132 -0.1790427  -0.12597148  0.38653599]\n",
      " [ 0.18780174  1.359331    0.72720043  0.16112177  0.46957084]\n",
      " [ 0.29719     1.39071639 -0.2176786   0.33265673 -0.78661063]\n",
      " [-2.45393088  0.66331603  0.77422638 -0.71835992  2.22831012]\n",
      " [-1.44224065  0.03042281 -0.191009    1.5156969   1.43911238]\n",
      " [ 0.15867103  0.40093815 -0.89692743 -1.96804046 -0.37080055]\n",
      " [ 0.1908643   1.20938128  1.1401879  -0.37404796 -0.26252425]\n",
      " [-1.03472557 -1.40793728 -1.6470542   1.85443223 -0.46420489]\n",
      " [-0.39440021 -1.22924194  0.7523645  -1.6153449  -0.1983415 ]\n",
      " [-0.89138021  0.38862101 -0.51612204 -1.18438563 -0.03217941]\n",
      " [ 0.42833187  0.06651722  0.3024719  -0.63432209 -0.36274117]\n",
      " [-0.67778842 -0.34744091 -0.79451177 -1.71727382  0.14865284]\n",
      " [-0.41149399 -1.61756526  0.46954703 -0.906951    0.03712755]\n",
      " [ 0.65971228  0.17875474  1.18964239 -1.2014783   0.31240966]\n",
      " [-0.6773059  -0.85923984 -0.57614006 -0.34611695  0.09587395]\n",
      " [-1.16925318  0.91744883  0.47179036 -1.54114059  1.47029555]\n",
      " [ 1.8916063   1.17365508 -0.17716922 -1.07043174  1.05422834]\n",
      " [-0.3870272   1.20809376  0.21391247  0.95563356  0.38436458]\n",
      " [ 0.82142045  0.02070452  1.43925759  0.25028702  0.42497007]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "word2idx, W, V = train_model()\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79979108 0.33298967]\n",
      "[[0.16974153 0.56550604]\n",
      " [0.15930054 0.53072116]\n",
      " [0.00803347 0.02676408]\n",
      " [0.07554102 0.2516703 ]]\n"
     ]
    }
   ],
   "source": [
    "W = np.random.randn(6, 4)\n",
    "V = np.random.randn(4, 6)\n",
    "prob = sigmoid(W[3].dot(V[:,[2, 4]]))\n",
    "print(prob)\n",
    "\n",
    "gV = np.outer(W[3], prob - 1)\n",
    "print(gV)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
